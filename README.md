# comment_analysis

### 1. 댓글 분석 과정

1. 댓글 토큰화

2. 이상적인 댓글 형성

    * 글로우픽 댓글 집합에서 중요한 단어 추출하기
        * TextRank
            1. 단어 사이의 연결을 고려하여 Word Graph 형성하기
            2. 그래프 내부 이동의 추이행렬 구하기
            3. 추이행렬의 곱셈을 통한 (Markov chain) 단어 중요도 추출하기
           의문점 : 
        * TF-IDF
            1. 문서에서의 단어의 출현 빈도에 기반한 Term Frequency 구하기
                * 이때 단순 빈도가 아닌 증가 빈도 사용 : 계산 시 문서의 길이 고려
            2. 여러 문서에서 공통적으로 출현하는 단어의 Inverse Document Frequency 구하기

    * 추출한 중요한 단어들로 이상적인 문장 구성하기
        * 순서는 크게 중요하지 않으므로 순열을 사용하여 문장 구성 **#1**
<hr/>

### Todo list
* 좋은 문장을 판별하는 척도 개발하기
* **#1** 에서 문장의 길이는 어느정도가 적당한지?
<hr/>

### 모듈별 함수 설명

#### Glowpick Tokenizer
* Replace comments with keywords

    이모티콘과 ㅋㅋ 등만 삭제한 댓글에서 브랜드명, 뷰티 관련 속어 등 (tokenize_keywords.csv 파일 참조) 을 숫자로 대체

* Tokenize comments

    Open Korean Text 토크나이저로 댓글 토크나이즈

* Fix comments

    숫자를 다시 브랜드명, 속어 등으로 대체

#### Keyword Extraction
* Get token pairs
    
    윈도우 사이즈 (디폴트 7) 맞춰서 댓글별 단어 페어를 만듦

* Get vocab
    
    댓글에 쓰인 모든 단어를 리스트에 추가
    
* Get matrix
    
    vocab 리스트 사이즈만한 정사각행렬을 만들고 한 단어에서 다른 단어로 가는 확률을 계산해서 i번째 단어에서 j번째 단어로 가는 확률을 해당하는 위치에 넣음

* Analyze
    
    행렬을 여러 번 곱해서 (마르코프 연쇄) 단어들의 연결의 경향성 파악 -> 마지막 나오는 행에 대해서 높은 확률을 갖는 단어가 중요한 단어

#### Sentence Extraction
* Similarity

    두 센텐스 사이의 유사도 계산 함수. 여기 좀 문제가 있어보여요. 분모는 문장의 단어 수에 로그를 취한 값으로써 문장이 길어지는걸 막는다는 취지인데, 로그를 취하면 길어질수록 증가율이 낮아지지 않나요? 긴 문장일수록 분모 증가율이 낮아져서 전체 값은 커지는 효과를 가져오는 거 같아서 개선 방안 찾는중…

* Get matrix

    문장 개수 * 문장 개수 행렬 만들고 문서 내의 모든 문장 사이의 유사도를 계산합니다 이때 순서쌍의 순서는 상관없기 때문에 행렬은 upper triangle 행렬이 되고 자기 자신과의 유사도는 무의미하므로 모든 대각성분은 0이 됩니다

* Get most important

    i번째 문장이 다른 모든 문장과 가지는 유사도를 합해서 비교해서 어떤게 제일 중요한 문장인지 추출. 이때 유사도의 합보다 더 좋은 방법이 있을 것 같아서 개선 방안 찾는중…